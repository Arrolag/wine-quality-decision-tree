---
title: "Decision Trees in R"
author: "Ruth Ogal"
date: "2025-03-26"
output: 
  html_document:
    toc: true
    toc_float: true
bibliography: ref_one.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


First, we load all the packages needed to complete this analysis.

```{r, comment=NA, warning=FALSE, message=FALSE}
library("rpart")
library("rpart.plot")
library("caret")
```


After loading the dataset in R, we subset it to form a new dataset called `white`, containing the first 11 columns of the original dataset and all rows having the `color` variable as `white`.

```{r, comment=NA}
df <- read.csv("C:/Users/User/Desktop/Decision_trees_Random_Forests/winequality-all.csv", comment.char="#")
# Create new dataset 
white <- df[df$color == "white", 1:11]
```

The target variable, `alcohol', is the 11th variable of `white`. We convert it  into a binary factor variable using the following code:

```{r, comment=NA}
white$alcohol <- factor(as.character(as.numeric(white$alcohol >= 12)))
table(white$alcohol)
```


Next, we split it into training (60%) and test (40%) sets.

```{r, comment=NA}
# Create a 60-40 split in the dataset
set.seed(123)
spt <- sample(1:nrow(white), round(nrow(white) * 0.6))
XY_train <- white[spt,]
XY_test <- white[-spt,]
```


## Build model

To build the decision tree, we use the `rpart()` from the package `rpart`. 

First, we build a full tree by setting `cp = 0` in the function `rpart.control()`. This function carries various parameters that can be tweaked to control This parameter, where `cp` is the complexity parameter. This parameter helps with controlling tree size by penalizing the addition of nodes to a tree. As such, the bigger it is, the less complex a tree becomes [@boehmke2019]  

After building the full tree, we prune it based on the value of the optimal $cp$. We can find this value by using the *1-SE rule*, which states that the best $cp$ value is that of the smallest tree within $1$ standard error of the minimum cross validation error, also called *xerror* in the *rpart* package. 

*rpart()* automatically performs a 10-fold cross validation when building a decision tree model. This behavior is controlled by the *xval* parameter of the *rpart.control()* function in *rpart()*, which is set to $10$ by default.


```{r, comment=NA}
fita <- rpart(alcohol~., data=XY_train, method="class", control = rpart.control(cp = 0))
```

Call the summary() function on the fitted model to get the following information:

+ A $cp$ table

+ A variable importance table

+ Tree node details, including node number,  number of observations, $cp$ value, probabilities, and split criteria.

To prune the tree, we must find the optimal $cp$ value. To obtain this value, we take a look at the $cp$ table. The table can be obtained in the following ways:

+ From *summary(model)*

+ From *model$cptable*

+ From *printcp(model)*

We want the smallest *xerror* in this table. We can find the index of this value by calling the *which.min()* function on the *xerror* column of *fita$cptable*, as shown below.

```{r, comment=NA}
which.min(fita$cptable[, 4])
```

From the 7th row, we find *xerror* $= 0.4657258$ and *xstd* $= 0.02941365$. So, the optimal decision tree is the smallest tree with an *xerror* $\le (0.4657258 + 0.02941365 = 0.4951395)$. The tree that meets this threshold has a $cp$ value of $0.013104839$.

Next, we use the *prune()* function to prune the full tree based on the optimal $cp$ value, as shown below.

```{r, comment=NA}
fitoptimal <- prune(fita, cp = 0.013104839)
```

We can also plot the pruned tree using *rpart.plot()*. See how simple it is!

```{r, comment=NA}
rpart.plot(fitoptimal)
```


## Model Evaluation

Before we can use the model to make predictions on the train data, we determine a baseline accuracy score for the model. We set this score as the proportion of the majority class.

```{r, comment=NA}
round(nrow(XY_train[XY_train$alcohol == 0, ])/nrow(XY_train), 3)
```

By comparing this score with the model's accuracy score, we can assess whether the model has learned meaningful patterns or performs worse than a naive model.

Next, we use the *predict()* function to make predictions on the train data.

```{r, comment=NA}
pred_train <- predict(fitoptimal, newdata = XY_train, type = "class")
```

We use the *confusionMatrix()* function from the *caret* package to compute a confusion matrix for evaluating the performance of the model on the training data.

```{r, comment=NA}
confusionMatrix(pred_train, XY_train$alcohol)
```

From the confusion matrix, we see that the model's training accuracy score is better than the baseline score

## References
